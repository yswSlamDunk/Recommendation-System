{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5617ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import argparse\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38909aa",
   "metadata": {},
   "source": [
    "# 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426901dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/Movie_Lens_100k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be0e7d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(path, 'ua.base'), sep = '\\t', names = ['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "test_df = pd.read_csv(os.path.join(path, 'ua.test'), sep = '\\t', names = ['user_id', 'movie_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c18419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_only_movie = list(set(test_df['movie_id'].unique().flatten()) - set(train_df['movie_id'].unique().flatten()))\n",
    "test_df = test_df[~test_df['movie_id'].isin(test_only_movie)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff01d7b3",
   "metadata": {},
   "source": [
    "### Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0016fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_le = LabelEncoder()\n",
    "movie_le = LabelEncoder()\n",
    "\n",
    "user_le.fit(train_df['user_id'])\n",
    "movie_le.fit(train_df['movie_id'])\n",
    "\n",
    "train_df['movie_id'] = movie_le.transform(train_df['movie_id'])\n",
    "train_df['user_id'] = user_le.transform(train_df['user_id'])\n",
    "\n",
    "test_df['movie_id'] = movie_le.transform(test_df['movie_id'])\n",
    "test_df['user_id'] = user_le.transform(test_df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0a49c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [   0,    1],\n",
       "       [   0,    2],\n",
       "       ...,\n",
       "       [ 942, 1187],\n",
       "       [ 942, 1227],\n",
       "       [ 942, 1329]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['user_id', 'movie_id']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5cb5d",
   "metadata": {},
   "source": [
    "# LightGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2051d2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, n_user, n_item, args, train_df):\n",
    "        super(LightGCN, self).__init__()\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.device = args.device\n",
    "        self.emb_size = args.embed_size\n",
    "        self.batch_size = args.batch_size\n",
    "        self.num_layers = args.num_layers\n",
    "        self.node_dropout = args.node_dropout\n",
    "        \n",
    "        self.split = args.split\n",
    "        self.num_folds = args.num_folds\n",
    "        self.reg = args.reg\n",
    "        \n",
    "        self.make_train_matrix(train_df)\n",
    "        \n",
    "        self.Graph = self.getSparseGraph()\n",
    "        self.data_loader = None # 이거는 추후에 확인할 필요 있음\n",
    "        \n",
    "        self.build_graph()\n",
    "    \n",
    "    def make_train_matrix(self, train_df):\n",
    "        rows, cols = train_df['user_id'], train_df['movie_id']\n",
    "        values = train_df['rating']\n",
    "        \n",
    "        sp_data = sp.csr_matrix((values, (rows, cols)), dtype = 'float64', shape = (self.n_user, self.n_item))\n",
    "        \n",
    "        self.train_matrix = sp_data\n",
    "    \n",
    "    def build_graph(self):\n",
    "        self.user_embedding = nn.Embedding(self.n_user, self.emb_size)\n",
    "        self.item_embedding = nn.Embedding(self.n_item, self.emb_size)\n",
    "        \n",
    "        # weight initalization\n",
    "        nn.init.normal_(self.user_embedding.weight, 0, 0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, 0, 0.01)\n",
    "        \n",
    "        self.to(self.device)\n",
    "        \n",
    "    def lightgcn_embedding(self, graph):\n",
    "        users_emb = self.user_embedding.weight\n",
    "        items_emb = self.item_embedding.weight\n",
    "        all_emb = torch.cat([users_emb, items_emb], dim = 0)\n",
    "        \n",
    "        embs = [all_emb]\n",
    "        \n",
    "        if self.node_dropout > 0 :\n",
    "            if self.training:\n",
    "                g_droped = self.__dropout(graph, self.node_dropout)\n",
    "                \n",
    "            else:\n",
    "                g_droped = graph\n",
    "                \n",
    "        else:\n",
    "            g_droped = graph\n",
    "            \n",
    "        ego_emb = all_emb\n",
    "        for k in range(self.num_layers):\n",
    "            if self.split:\n",
    "                tmp_emb = []\n",
    "                for f in range(len(g_droped)):\n",
    "                    tmp_emb.append(torch.sparse.mm(g_droped[f], ego_emb))\n",
    "                side_emb = torch.cat(temp_emb, dim = 0)\n",
    "                all_emb = side_emb\n",
    "                \n",
    "            else:\n",
    "                all_emb = torch.sparse.mm(g_droped, all_emb)\n",
    "            embs.append(all_emb)\n",
    "            \n",
    "        embs = torch.stack(embs, dim = 1)\n",
    "        lightgcn_out = torch.mean(embs, dim = 1)\n",
    "        users, items = torch.split(lightgcn_out, [self.n_user, self.n_item])\n",
    "        \n",
    "        return users, items\n",
    "        \n",
    "    def _split_A_hat(self, A):\n",
    "        A_fold = []\n",
    "        fold_len = (self.n_user + self.n_item) // self.num_folds\n",
    "        \n",
    "        for i_fold in range(self.num_folds):\n",
    "            start = i_fold * fold_len\n",
    "            if i_fold == self.num_folds -1:\n",
    "                end = self.n_user + self.n_item\n",
    "            else:\n",
    "                end = (i_fold + 1) * fold_len\n",
    "            A__fold.append(self._convert_sp_mat_to_sp_tensor(A[start:end]).coalesce().to(self.device))\n",
    "        return A_fold\n",
    "    \n",
    "    def _convert_sp_mat_to_sp_tensor(self, X):\n",
    "        coo = X.tocoo().astype(np.float32)\n",
    "        row = torch.Tensor(coo.row).long()\n",
    "        col = torch.Tensor(coo.col).long()\n",
    "        index = torch.stack([row, col])\n",
    "        data = torch.FloatTensor(coo.data)\n",
    "        return torch.sparse.FloatTensor(index, data, torch.Size(coo.shape))\n",
    "    \n",
    "    def getSparseGraph(self):\n",
    "        n_users, n_items = self.train_matrix.shape\n",
    "        \n",
    "        adj_mat = sp.dok_matrix((n_users + n_items, n_users + n_items), dtype = np.float32)\n",
    "        adj_mat = adj_mat.tolil()\n",
    "        R = rating_matrix.tolil()\n",
    "        adj_mat[:n_users, n_users:] = R\n",
    "        adj_mat[n_users:, :n_users] = R.T\n",
    "        adj_mat = adj_mat.todok()\n",
    "        \n",
    "        rowsum = np.array(adj_mat.sum(axis = 1))\n",
    "        d_inv = np.power(rowsum, -0.5).flatten()\n",
    "        d_inv[np.isinf(d_inv)] = 0.\n",
    "        d_mat = sp.diags(d_inv)\n",
    "        \n",
    "        norm_adj = d_mat.dot(adj_mat)\n",
    "        norm_adj = norm_adj.dot(d_mat)\n",
    "        norm_adj = norm_adj.tocsr()\n",
    "        \n",
    "        if self.split == True:\n",
    "            Graph = self._split_A_hat(norm_adj)\n",
    "        \n",
    "        else:\n",
    "            Graph = self._convert_sp_mat_to_sp_tensor(norm_adj)\n",
    "            Graph = Graph.coalesce().to(self.device)\n",
    "            \n",
    "        return Graph\n",
    "    \n",
    "    def predict_batch_users(self, user_ids):\n",
    "        user_embeddings = F.embedding(user_ids, self.user_embedding_pred)\n",
    "        item_embeddings = self.item_Embedding_pred\n",
    "        return np.matmul(user_embeddings, item_embeddings.T)\n",
    "    \n",
    "    def forward(self, user, item):\n",
    "        u_embedding, i_embedding = self.lightgcn_embedding(self.Graph)\n",
    "        \n",
    "        user_latent = F.embedding(user, u_embedding)\n",
    "        item_latent = F.embedding(item, i_embedding)\n",
    "        \n",
    "        score = torch.mul(user_latent, item_latent).sum(1)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "287766e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        user = torch.tensor(row[0], dtype = torch.long)\n",
    "        item = torch.tensor(row[1], dtype = torch.long)\n",
    "        label = torch.tensor(row[2], dtype = torch.float)\n",
    "        \n",
    "        return user, item, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd87b5",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b707a9d",
   "metadata": {},
   "source": [
    "### argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3ba7a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--lr'], dest='lr', nargs=None, const=None, default=0.001, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description = 'Run LightGCN')\n",
    "parser.add_argument('--embed_size', default = 64)\n",
    "parser.add_argument('--num_layers', default = 2)\n",
    "parser.add_argument('--node_dropout', default = 0.3)\n",
    "parser.add_argument('--split', default = False)\n",
    "parser.add_argument('--num_folds', default = 100)\n",
    "parser.add_argument('--reg', default = 1e-3)\n",
    "parser.add_argument('--epochs', default = 40)\n",
    "parser.add_argument('--batch_size', default = 1024)\n",
    "parser.add_argument('--lr', default = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "34d2130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(indices=tensor([[   0,    0,    0,  ..., 2620, 2621, 2622],\n",
      "                       [ 943,  944,  945,  ...,  862,  895,  915]]),\n",
      "       values=tensor([0.0042, 0.0050, 0.0081,  ..., 0.0819, 0.0534, 0.0538]),\n",
      "       size=(2623, 2623), nnz=181140, layout=torch.sparse_coo)\n",
      "tensor([0.0042, 0.0050, 0.0081,  ..., 0.0819, 0.0534, 0.0538])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'g_droped' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6051/997171689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mhat_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhat_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn_rec/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6051/1969606069.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user, item)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mu_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightgcn_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0muser_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6051/1969606069.py\u001b[0m in \u001b[0;36mlightgcn_embedding\u001b[0;34m(self, graph)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mall_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_droped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'g_droped' referenced before assignment"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args('')\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n_user = train_df['user_id'].nunique()\n",
    "n_item = train_df['movie_id'].nunique()\n",
    "\n",
    "model = LightGCN(n_user, n_item, args, train_df)\n",
    "optimizer = optim.Adam(model.parameters(), lr = args.lr)\n",
    "\n",
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = args.batch_size, shuffle = True)\n",
    "\n",
    "train_loss_loger, test_loss_loger = [], []\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for users, items, labels in train_dataloader:\n",
    "        hat_labels = model(users, items)\n",
    "        batch_loss = criterion(hat_labels, labels)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += batch_loss.item() / len(train_dataloader)\n",
    "        \n",
    "    train_loss_loger.append(train_loss)\n",
    "    \n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for users, items, labels in test_dataloader:\n",
    "            hat_labels = model(users, items)\n",
    "            batch_loss = criterion(hat_labels, labels)\n",
    "            test_loss += batch_loss.item() / len(test_dataloader)\n",
    "            \n",
    "        test_loss_loger.append(test_loss)\n",
    "        \n",
    "    print('epoch : {}, train_loss : {}, test_loss : {}'.format(epoch, round(train_loss, 4), round(test_loss, 4)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55e28af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f6cfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72476a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, train_loss : 11.7921, test_loss : 9.1175\n",
      "epoch : 1, train_loss : 3.9549, test_loss : 3.2602\n",
      "epoch : 2, train_loss : 2.1307, test_loss : 2.8058\n",
      "epoch : 3, train_loss : 1.9053, test_loss : 2.5529\n",
      "epoch : 4, train_loss : 1.7366, test_loss : 2.3437\n",
      "epoch : 5, train_loss : 1.5994, test_loss : 2.2105\n",
      "epoch : 6, train_loss : 1.488, test_loss : 2.0135\n",
      "epoch : 7, train_loss : 1.3955, test_loss : 1.9432\n",
      "epoch : 8, train_loss : 1.3179, test_loss : 1.7821\n",
      "epoch : 9, train_loss : 1.2539, test_loss : 1.7169\n",
      "epoch : 10, train_loss : 1.1986, test_loss : 1.6017\n",
      "epoch : 11, train_loss : 1.1533, test_loss : 1.5254\n",
      "epoch : 12, train_loss : 1.1138, test_loss : 1.4765\n",
      "epoch : 13, train_loss : 1.081, test_loss : 1.4023\n",
      "epoch : 14, train_loss : 1.052, test_loss : 1.3585\n",
      "epoch : 15, train_loss : 1.0271, test_loss : 1.3191\n",
      "epoch : 16, train_loss : 1.0067, test_loss : 1.2871\n",
      "epoch : 17, train_loss : 0.9875, test_loss : 1.221\n",
      "epoch : 18, train_loss : 0.9727, test_loss : 1.2023\n",
      "epoch : 19, train_loss : 0.9597, test_loss : 1.1707\n",
      "epoch : 20, train_loss : 0.9463, test_loss : 1.1307\n",
      "epoch : 21, train_loss : 0.9355, test_loss : 1.1249\n",
      "epoch : 22, train_loss : 0.9261, test_loss : 1.1135\n",
      "epoch : 23, train_loss : 0.9193, test_loss : 1.0752\n",
      "epoch : 24, train_loss : 0.9108, test_loss : 1.0675\n",
      "epoch : 25, train_loss : 0.9058, test_loss : 1.0621\n",
      "epoch : 26, train_loss : 0.9, test_loss : 1.0477\n",
      "epoch : 27, train_loss : 0.895, test_loss : 1.0322\n",
      "epoch : 28, train_loss : 0.8895, test_loss : 1.0295\n",
      "epoch : 29, train_loss : 0.8857, test_loss : 1.0128\n",
      "epoch : 30, train_loss : 0.8823, test_loss : 1.013\n",
      "epoch : 31, train_loss : 0.8795, test_loss : 0.99\n",
      "epoch : 32, train_loss : 0.8768, test_loss : 0.9988\n",
      "epoch : 33, train_loss : 0.8738, test_loss : 0.9729\n",
      "epoch : 34, train_loss : 0.871, test_loss : 0.9797\n",
      "epoch : 35, train_loss : 0.8685, test_loss : 0.9684\n",
      "epoch : 36, train_loss : 0.8676, test_loss : 0.9851\n",
      "epoch : 37, train_loss : 0.8659, test_loss : 0.9606\n",
      "epoch : 38, train_loss : 0.8636, test_loss : 0.9736\n",
      "epoch : 39, train_loss : 0.862, test_loss : 0.9569\n"
     ]
    }
   ],
   "source": [
    "args = parser.parse_args('')\n",
    "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "n_user = train_df['user_id'].nunique()\n",
    "n_item = train_df['movie_id'].nunique()\n",
    "\n",
    "model = LightGCN(n_user, n_item, args, train_df)\n",
    "optimizer = optim.Adam(model.parameters(), lr = args.lr)\n",
    "\n",
    "train_dataset = CustomDataset(train_df)\n",
    "test_dataset = CustomDataset(test_df)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = args.batch_size, shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = args.batch_size, shuffle = True)\n",
    "\n",
    "train_loss_loger, test_loss_loger = [], []\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    for users, items, labels in train_dataloader:\n",
    "        hat_labels = model(users, items)\n",
    "        batch_loss = criterion(hat_labels, labels)\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += batch_loss.item() / len(train_dataloader)\n",
    "        \n",
    "    train_loss_loger.append(train_loss)\n",
    "    \n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for users, items, labels in test_dataloader:\n",
    "            hat_labels = model(users, items)\n",
    "            batch_loss = criterion(hat_labels, labels)\n",
    "            test_loss += batch_loss.item() / len(test_dataloader)\n",
    "            \n",
    "        test_loss_loger.append(test_loss)\n",
    "        \n",
    "    print('epoch : {}, train_loss : {}, test_loss : {}'.format(epoch, round(train_loss, 4), round(test_loss, 4)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28613b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_rec",
   "language": "python",
   "name": "gnn_rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
